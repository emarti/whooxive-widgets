{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fancy machine learning to predict whether an article makes it into Nature/Science or PRL. This time we'll only look at articles in the physics.atom-ph section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Need to add parent directoy to sys.path to find 'metadataDB'\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "# Natural language processing toolkit\n",
    "# To use this, run nltk.download() and download 'stopwords'\n",
    "# from nltk.corpus import stopwords\n",
    "# s=stopwords.words('english') + ['']\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# SQL\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from metadataDB.declareDatabase import *\n",
    "from sqlalchemy import or_, and_\n",
    "\n",
    "engine = create_engine(\"sqlite:///../arXiv_metadata.db\", echo=False)\n",
    "Base.metadata.bind = engine\n",
    "DBsession = sessionmaker(bind=engine)\n",
    "session = DBsession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['astro-ph', 'atom-ph', 'cond-mat', 'hep-th', 'hep-ex', 'quant-ph']\n",
    "# categories = ['atom-ph', 'quant-ph']\n",
    "journals_dict = {'PRL': ['Physics Review Letters%',\n",
    "                    'Phys. Rev. Lett.%',\n",
    "                    'Phys.Rev.Lett.%',\n",
    "                    'PRL%'],\n",
    "                 'PR':  ['Physics Review%',\n",
    "                         'Phys. Rev.%',\n",
    "                         'Phys.Rev.%',\n",
    "                         'PR%'],\n",
    "                 'Nature': ['Nature%',\n",
    "                            'Nat.%',\n",
    "                            'Science%'],\n",
    "                 'APL': ['APL%',\n",
    "                         'Appl.Phys.Lett.%',\n",
    "                         'Appl. Phys. Lett.%',\n",
    "                         'Applied Physics Letters%'],\n",
    "                 'AP': ['AP%',\n",
    "                        'Appl.Phys.%',\n",
    "                        'Appl. Phys.%',\n",
    "                        'Applied Physics%'],\n",
    "                 'PL': ['Physics Letters%',\n",
    "                        'Phys. Lett.%',\n",
    "                        'Phys.Lett.%'],\n",
    "                 'All': ['%'],\n",
    "                 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_abstracts(category):\n",
    "    query = session.query(Article_Category)\\\n",
    "                    .join(Category)\\\n",
    "                    .join(Article)\\\n",
    "                    .filter(Category.name.like('%' + category + '%'),\n",
    "                            or_(*[Article.journal_ref.like(x)\n",
    "                                  for x in journals_dict['Nature']+journals_dict['PR']]))\n",
    "#                                   for x in journals_dict['Nature']+journals_dict['PRL']]))\n",
    "\n",
    "                \n",
    "    # Don't need to clean up text: CountVectorizer will do everything\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('astro-ph', 3.97485613822937, 13027)\n",
      "('atom-ph', 7.043087005615234, 2404)\n",
      "('cond-mat', 12.409974098205566, 66018)\n",
      "('hep-th', 16.21687912940979, 13135)\n",
      "('hep-ex', 19.63132905960083, 6156)\n",
      "('quant-ph', 23.21168613433838, 14844)\n",
      "23.2522759438\n"
     ]
    }
   ],
   "source": [
    "# Some abstract have multiple categories. I'll make a dict based on the article\n",
    "# id number to link these labels.\n",
    "# \n",
    "# Train with at least 500 abstracts per category, so as not to overlook\n",
    "# a small category (like atom-ph). At least because many categories are\n",
    "# multiply listed\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# These numbers are based on the 2401 atom-ph articles in the database.\n",
    "articles_per_category_train = 2000\n",
    "articles_per_category_test = 400\n",
    "\n",
    "query_list = []\n",
    "for category in categories:\n",
    "    current_abstracts = get_abstracts(category)\n",
    "    query_list.append(get_abstracts(category))\n",
    "#     break\n",
    "    \n",
    "abstract_dict_test = dict()\n",
    "category_dict_test = dict()\n",
    "category_to_number_test = dict(zip(categories, range(0, len(categories))))\n",
    "\n",
    "abstract_dict_train = dict()\n",
    "category_dict_train = dict()\n",
    "category_to_number_train = dict(zip(categories, range(0, len(categories))))\n",
    "\n",
    "for q, category in zip(query_list, categories):\n",
    "    q = q.all() # this line really speeds things up!\n",
    "    ind = np.random.choice(len(q),\n",
    "                              articles_per_category_train+articles_per_category_test,\n",
    "                              replace=False)\n",
    "    \n",
    "    # Training set\n",
    "    for i in ind[:articles_per_category_train]:\n",
    "#     for x in q:\n",
    "        x = q[i]\n",
    "        abstract_dict_train[x.article.id] = x.article.abstract\n",
    "        try:\n",
    "            category_dict_train[x.article.id].append(category)\n",
    "        except KeyError:\n",
    "            category_dict_train[x.article.id] = [category]\n",
    "    \n",
    "    # Testing set\n",
    "    for i in ind[articles_per_category_train:]:\n",
    "        x = q[i]\n",
    "        abstract_dict_test[x.article.id] = x.article.abstract\n",
    "        try:\n",
    "            category_dict_test[x.article.id].append(category)\n",
    "        except KeyError:\n",
    "            category_dict_test[x.article.id] = [category]\n",
    "    \n",
    "    print (category, (time.time() - start), len(q))\n",
    "    \n",
    "keys_train = abstract_dict_train.keys()\n",
    "keys_test = abstract_dict_test.keys()\n",
    "\n",
    "label_binarizer = MultiLabelBinarizer(classes=categories)\n",
    "\n",
    "\n",
    "X_train = [abstract_dict_train[key] for key in keys_train]\n",
    "Y_train = label_binarizer.fit_transform([ category_dict_train[key] for key in keys_train])\n",
    "\n",
    "X_test = [abstract_dict_test[key] for key in keys_test]\n",
    "Y_test = label_binarizer.fit_transform([ category_dict_test[key] for key in keys_test])\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.589030981\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_category = OneVsRestClassifier(Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC(C=10,penalty='l1',dual=False,fit_intercept=True))]))\n",
    "clf_category.fit(X_train, Y_train)\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To save memory, I will retrain the countvectorizer on only the nonzero entries to the coefficient matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9863\n",
      "27.0100297928\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "useful_words = []\n",
    "\n",
    "for x in clf_category.estimators_:\n",
    "#     print x\n",
    "    nonzero_coefs = np.nonzero(np.squeeze(x.named_steps['clf'].coef_))[0]\n",
    "    useful_words.extend(np.array(x.named_steps['vect'].get_feature_names())[nonzero_coefs])\n",
    "\n",
    "useful_words = list(set(useful_words))\n",
    "print len(useful_words)\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.9926068783\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_category2 = OneVsRestClassifier(Pipeline([('vect', CountVectorizer(ngram_range=(1,3), vocabulary=useful_words)),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC(C=10,penalty='l1',dual=False,fit_intercept=True))]))\n",
    "clf_category2.fit(X_train, Y_train)\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a classification report for each category.\n",
    "def classification_report(clf):\n",
    "    Y_pred = clf.predict(X_test)\n",
    "\n",
    "    for i, category in enumerate(categories):\n",
    "        print metrics.classification_report(Y_test[:,i], Y_pred[:,i], target_names=['not '+category, category])\n",
    "        print metrics.accuracy_score(Y_test[:,i], Y_pred[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "not astro-ph       0.94      0.94      0.94      1987\n",
      "    astro-ph       0.69      0.72      0.71       400\n",
      "\n",
      " avg / total       0.90      0.90      0.90      2387\n",
      "\n",
      "0.899036447424\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "not atom-ph       0.96      0.94      0.95      1987\n",
      "    atom-ph       0.71      0.78      0.74       400\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2387\n",
      "\n",
      "0.909509844994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not cond-mat       0.95      0.94      0.94      1987\n",
      "    cond-mat       0.71      0.74      0.73       400\n",
      "\n",
      " avg / total       0.91      0.91      0.91      2387\n",
      "\n",
      "0.906996229577\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " not hep-th       0.94      0.93      0.93      1987\n",
      "     hep-th       0.66      0.69      0.67       400\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2387\n",
      "\n",
      "0.888563049853\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " not hep-ex       0.98      0.98      0.98      1987\n",
      "     hep-ex       0.89      0.90      0.89       400\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2387\n",
      "\n",
      "0.963552576456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not quant-ph       0.93      0.93      0.93      1987\n",
      "    quant-ph       0.64      0.64      0.64       400\n",
      "\n",
      " avg / total       0.88      0.88      0.88      2387\n",
      "\n",
      "0.878508588186\n"
     ]
    }
   ],
   "source": [
    "classification_report(clf_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "not astro-ph       0.93      0.94      0.94      1987\n",
      "    astro-ph       0.69      0.68      0.68       400\n",
      "\n",
      " avg / total       0.89      0.90      0.90      2387\n",
      "\n",
      "0.895684960201\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "not atom-ph       0.95      0.95      0.95      1987\n",
      "    atom-ph       0.74      0.73      0.74       400\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2387\n",
      "\n",
      "0.912023460411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not cond-mat       0.94      0.95      0.94      1987\n",
      "    cond-mat       0.73      0.69      0.71       400\n",
      "\n",
      " avg / total       0.90      0.91      0.90      2387\n",
      "\n",
      "0.905739421868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " not hep-th       0.93      0.94      0.94      1987\n",
      "     hep-th       0.69      0.64      0.66       400\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2387\n",
      "\n",
      "0.891914537076\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " not hep-ex       0.97      0.98      0.98      1987\n",
      "     hep-ex       0.90      0.87      0.89       400\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2387\n",
      "\n",
      "0.963133640553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not quant-ph       0.92      0.94      0.93      1987\n",
      "    quant-ph       0.67      0.61      0.64       400\n",
      "\n",
      " avg / total       0.88      0.88      0.88      2387\n",
      "\n",
      "0.884792626728\n"
     ]
    }
   ],
   "source": [
    "classification_report(clf_category2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('atom-ph',)]\n",
      "[('atom-ph',)]\n"
     ]
    }
   ],
   "source": [
    "current_abstract = ['We measure the mass, gap, and magnetic moment of a magnon in the ferromagnetic F=1 spinor Bose-Einstein condensate of 87Rb. We find an unusually heavy magnon mass of 1.038(2)stat(8)sys times the atomic mass, as determined by interfering standing and running coherent magnon waves within the dense and trapped condensed gas. This measurement is shifted significantly from theoretical estimates. The magnon energy gap of h×2.5(1)stat(2)sysHz and the effective magnetic moment of −1.04(2)stat(8)μbare times the atomic magnetic moment are consistent with mean-field predictions. The nonzero energy gap arises from magnetic dipole-dipole interactions.']\n",
    "print label_binarizer.inverse_transform(clf_category.predict(current_abstract))\n",
    "print label_binarizer.inverse_transform(clf_category2.predict(current_abstract))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[()]\n",
      "[()]\n"
     ]
    }
   ],
   "source": [
    "current_abstract = ['Ultracold gases promise access to many-body quantum phenomena at convenient length and time scales. However, it is unclear whether the entropy of these gases is low enough to realize many phenomena relevant to condensed matter physics, such as quantum magnetism. Here we report reliable single-shot temperature measurements of a degenerate 87Rb gas by imaging the momentum distribution of thermalized magnons, which are spin excitations of the atomic gas. We record average temperatures as low as 0.022(1)stat(2)sys times the Bose-Einstein condensation temperature, indicating an entropy per particle, S/N≈0.001kB at equilibrium, that is well below the critical entropy for antiferromagnetic ordering of a Bose-Hubbard system. The magnons themselves can reduce the temperature of the system by absorbing energy during thermalization and by enhancing evaporative cooling, allowing low-entropy gases to be produced within deep traps.']\n",
    "print label_binarizer.inverse_transform(clf_category.predict(current_abstract))\n",
    "print label_binarizer.inverse_transform(clf_category2.predict(current_abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "joblib.dump((clf_category, label_binarizer), 'svm_category_old.pkl', compress=1)\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "joblib.dump((clf_category2, label_binarizer), 'svm_category.pkl', compress=1)\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('category_list.json', 'wb') as f:\n",
    "    category_list = categories\n",
    "    json.dump(category_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
