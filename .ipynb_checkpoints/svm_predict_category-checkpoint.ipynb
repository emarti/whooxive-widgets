{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fancy machine learning to predict whether an article makes it into Nature/Science or PRL. This time we'll only look at articles in the physics.atom-ph section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Need to add parent directoy to sys.path to find 'metadataDB'\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "# Natural language processing toolkit\n",
    "# To use this, run nltk.download() and download 'stopwords'\n",
    "# from nltk.corpus import stopwords\n",
    "# s=stopwords.words('english') + ['']\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# SQL\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from metadataDB.declareDatabase import *\n",
    "from sqlalchemy import or_, and_\n",
    "\n",
    "engine = create_engine(\"sqlite:///../arXiv_metadata.db\", echo=False)\n",
    "Base.metadata.bind = engine\n",
    "DBsession = sessionmaker(bind=engine)\n",
    "session = DBsession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['atom-ph', 'chem-ph', 'cond-mat', 'hep-th', 'hep-ex', 'quant-ph']\n",
    "# categories = ['atom-ph', 'quant-ph']\n",
    "journals_dict = {'PRL': ['Physics Review Letters%',\n",
    "                    'Phys. Rev. Lett.%',\n",
    "                    'Phys.Rev.Lett.%',\n",
    "                    'PRL%'],\n",
    "                 'PR':  ['Physics Review%',\n",
    "                         'Phys. Rev.%',\n",
    "                         'Phys.Rev.%',\n",
    "                         'PR%'],\n",
    "                 'Nature': ['Nature%',\n",
    "                            'Nat.%',\n",
    "                            'Science%'],\n",
    "                 'APL': ['APL%',\n",
    "                         'Appl.Phys.Lett.%',\n",
    "                         'Appl. Phys. Lett.%',\n",
    "                         'Applied Physics Letters%'],\n",
    "                 'AP': ['AP%',\n",
    "                        'Appl.Phys.%',\n",
    "                        'Appl. Phys.%',\n",
    "                        'Applied Physics%'],\n",
    "                 'PL': ['Physics Letters%',\n",
    "                        'Phys. Lett.%',\n",
    "                        'Phys.Lett.%'],\n",
    "                 'All': ['%'],\n",
    "                 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_abstracts(category):\n",
    "    query = session.query(Article_Category)\\\n",
    "                    .join(Category)\\\n",
    "                    .join(Article)\\\n",
    "                    .filter(Category.name.like('%' + category + '%'),\n",
    "                            or_(*[Article.journal_ref.like(x)\n",
    "                                  for x in journals_dict['Nature']+journals_dict['PRL']]))\n",
    "#                                   for x in journals_dict['Nature']+journals_dict['PRL']]))\n",
    "\n",
    "                \n",
    "    # Don't need to clean up text: CountVectorizer will do everything\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.0484337807\n"
     ]
    }
   ],
   "source": [
    "# Some abstract have multiple categories. I'll make a dict based on the article\n",
    "# id number to link these labels.\n",
    "start = time.time()\n",
    "\n",
    "query_list = []\n",
    "for category in categories:\n",
    "    query_list.append(get_abstracts(category))\n",
    "    \n",
    "abstract_dict = dict()\n",
    "category_dict = dict()\n",
    "category_to_number = dict(zip(categories, range(0, len(categories))))\n",
    "\n",
    "\n",
    "for q, category in zip(query_list, categories):\n",
    "    for x in q:\n",
    "        abstract_dict[x.article.id] = x.article.abstract\n",
    "        try:\n",
    "            category_dict[x.article.id].append(category)\n",
    "        except KeyError:\n",
    "            category_dict[x.article.id] = [category]\n",
    "keys = abstract_dict.keys()\n",
    "\n",
    "\n",
    "label_binarizer = MultiLabelBinarizer(classes=categories)\n",
    "\n",
    "\n",
    "X_train_tmp = [abstract_dict[key] for key in keys]\n",
    "Y_train_tmp = label_binarizer.fit_transform([ category_dict[key] for key in keys])\n",
    "\n",
    "X_train, _, Y_train, _ = train_test_split(X_train_tmp, Y_train_tmp, train_size=2000)\n",
    "\n",
    "# Y_train_tmp = [ [category_to_number[x] for x in category_dict[key]] for key in keys]\n",
    "\n",
    "# With 0.17, we have to use MultiLabelBinarizer\n",
    "# label_binarizer = MultiLabelBinarizer(classes=categories)\n",
    "# Y_train = label_binarizer.fit_transform(Y_train_tmp)\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# 70 MB is about 2600 abstracts... not many!\n",
    "print len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.1282448769\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf_category = OneVsRestClassifier(Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC(C=1,penalty='l1',dual=False,fit_intercept=True))]))\n",
    "clf_category.fit(X_train, Y_train)\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cond-mat',)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf_category.predict(['We measure the mass, gap, and magnetic moment of a magnon in the ferromagnetic F=1 spinor Bose-Einstein condensate of 87Rb. We find an unusually heavy magnon mass of 1.038(2)stat(8)sys times the atomic mass, as determined by interfering standing and running coherent magnon waves within the dense and trapped condensed gas. This measurement is shifted significantly from theoretical estimates. The magnon energy gap of h×2.5(1)stat(2)sysHz and the effective magnetic moment of −1.04(2)stat(8)μbare times the atomic magnetic moment are consistent with mean-field predictions. The nonzero energy gap arises from magnetic dipole-dipole interactions.'])\n",
    "\n",
    "label_binarizer.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cond-mat', 'quant-ph')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf_category.predict(['Ultracold gases promise access to many-body quantum phenomena at convenient length and time scales. However, it is unclear whether the entropy of these gases is low enough to realize many phenomena relevant to condensed matter physics, such as quantum magnetism. Here we report reliable single-shot temperature measurements of a degenerate 87Rb gas by imaging the momentum distribution of thermalized magnons, which are spin excitations of the atomic gas. We record average temperatures as low as 0.022(1)stat(2)sys times the Bose-Einstein condensation temperature, indicating an entropy per particle, S/N≈0.001kB at equilibrium, that is well below the critical entropy for antiferromagnetic ordering of a Bose-Hubbard system. The magnons themselves can reduce the temperature of the system by absorbing energy during thermalization and by enhancing evaporative cooling, allowing low-entropy gases to be produced within deep traps.'])\n",
    "\n",
    "label_binarizer.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print metrics.classification_report(Y_train, clf.predict(X_train))\n",
    "#                                     target_names=test_target_names))\n",
    "# print metrics.confusion_matrix(y_test, y_predict_test)\n",
    "# print 'Accuracy: %f' % (metrics.accuracy_score(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "joblib.dump((clf_category, label_binarizer), 'svm_category.pkl', compress=1)\n",
    "\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('category_list.json', 'wb') as f:\n",
    "    category_list = categories\n",
    "    json.dump(category_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
